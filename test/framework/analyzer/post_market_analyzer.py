# ===============================
# test/framework/analyzer/post_market_analyzer.py
# ===============================
"""
Post-Market Analyzer

ì •ì°°ë´‡ì´ ìˆ˜ì§‘í•œ JSONL ê¸°ë¡ì„ ë¶„ì„í•˜ì—¬:
- Observer/Reason ì§‘ê³„
- ì‹œì¥ ì„±ê²© ìš”ì•½ ìƒì„±
- ì¼ì¼ í‰ê°€ ê¸°ë¡ ì €ì¥
"""
import os
import json
from datetime import datetime
from typing import Dict, Any, List, Optional
from collections import defaultdict, Counter
from pathlib import Path


# ===============================
# ê²½ë¡œ ì„¤ì •
# ===============================
PROJECT_ROOT = os.path.abspath(
    os.path.join(os.path.dirname(__file__), "../../..")
)
SCOUT_RECORDS_DIR = os.path.join(PROJECT_ROOT, "records", "scout")
ANALYSIS_OUTPUT_DIR = os.path.join(PROJECT_ROOT, "records", "analysis")
os.makedirs(ANALYSIS_OUTPUT_DIR, exist_ok=True)


# ===============================
# ì œì™¸í•  ë‚ ì§œ ëª©ë¡ (í…ŒìŠ¤íŠ¸/ë¹„ì •ìƒ ë°ì´í„°)
# ===============================
EXCLUDED_DATES = {
    "2026-01-05",  # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì œì™¸
    "2026-01-06",  # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì œì™¸
}

# ì²« ì •ìƒ ë°ì´í„° ë‚ ì§œ
FIRST_VALID_DATE = "2026-01-07"


# ===============================
# JSONL ì½ê¸°
# ===============================
def load_scout_records(date: str) -> List[Dict[str, Any]]:
    """íŠ¹ì • ë‚ ì§œì˜ ëª¨ë“  ì •ì°° ê¸°ë¡ ë¡œë“œ"""
    # âœ… ì œì™¸ëœ ë‚ ì§œëŠ” ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    if date in EXCLUDED_DATES:
        msg = f"  âš ï¸  {date}ëŠ” ë¶„ì„ì—ì„œ ì œì™¸ëœ ë‚ ì§œì…ë‹ˆë‹¤ (í…ŒìŠ¤íŠ¸ ë°ì´í„°)"
        print(msg)
        return []
    
    date_dir = os.path.join(SCOUT_RECORDS_DIR, date)
    
    if not os.path.exists(date_dir):
        return []
    
    all_records = []
    
    # ëª¨ë“  .jsonl íŒŒì¼ ì½ê¸°
    for file_path in Path(date_dir).glob("*.jsonl"):
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        record = json.loads(line)
                        all_records.append(record)
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸  JSON íŒŒì‹± ì˜¤ë¥˜ ({file_path}): {e}")
        except Exception as e:
            print(f"âš ï¸  íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ ({file_path}): {e}")
    
    return all_records


# ===============================
# Observer/Reason ì§‘ê³„
# ===============================
def aggregate_observers(records: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Observer ê²°ê³¼ ì§‘ê³„ (Cycle íŒì • í¬í•¨)
    
    ìš©ì–´ ì •ì˜:
    - record: observerê°€ í•œ ë²ˆ ì‹¤í–‰ëœ ë¡œê·¸
    - trigger: ê´€ì¸¡ ì¡°ê±´ì„ ë§Œì¡±í•œ 'ì‚¬ê±´'
    - cycle: íŠ¸ë¦¬ê±° ì´í›„ ìœ ì§€, ì¢…ë£Œê¹Œì§€ì˜ ë¬¶ìŒ
        * ì‹œì‘: observer.triggered == True (ì´ì „ cycle ì¢…ë£Œ í›„ ì²« trigger)
        * ì¢…ë£Œ: outcome.exit_type ì¡´ì¬ (v1 í—ˆìš©: reached_1pct, no_reaction, timeout, manual_stop)
        * ì¢…ëª©ë³„ë¡œ ë™ì‹œì— 1ê°œë§Œ ì¡´ì¬ (ìƒíƒœ ë¨¸ì‹ : IDLE/ACTIVE)
    
    exit_type íŒì • ê¸°ì¤€:
    - exit_typeì€ ë°˜ë“œì‹œ í•˜ë‚˜ë§Œ
    - ìˆ«ìë³´ë‹¤ ì´ë²¤íŠ¸ ê¸°ì¤€
    - ì„±ê³¼/ì„±ê³µ/ì‹¤íŒ¨ ìš©ì–´ ê¸ˆì§€
    - v1 í—ˆìš© exit_type: reached_1pct, no_reaction, timeout, manual_stop
    """
    from datetime import datetime
    
    stats = {
        "total_records": len(records),
        "by_stock": defaultdict(lambda: {
            "records": 0,
            "triggered_records": 0,
            "box_formed": 0,
            "base_candle_exists": 0,
        }),
        "observer_summary": {
            "triggered_records": 0,
            "triggered_stocks": set(),
            "triggers": [],
            "triggered_cycle": [],  # ì™„ì „íˆ ì¢…ë£Œëœ cycle ëª©ë¡
            "open_cycles_count": 0,  # ì¥ ì¢…ë£Œ ì‹œì  ë¯¸ì¢…ë£Œ cycle ìˆ˜
        },
        "box_summary": {
            "formed_count": 0,
            "formed_stocks": set(),
        },
        "base_candle_summary": {
            "exists_count": 0,
            "exists_stocks": set(),
        },
        "session_distribution": Counter(),
        "no_event_reasons": Counter(),
    }
    
    # ============================================================
    # exit_type íŒì • ê¸°ì¤€ (v1 ê³ ì •)
    # ============================================================
    # ëŒ€ì›ì¹™:
    # 1. exit_typeì€ ë°˜ë“œì‹œ í•˜ë‚˜ë§Œ
    # 2. ìˆ«ìë³´ë‹¤ ì´ë²¤íŠ¸ ê¸°ì¤€
    # 3. ì„±ê³¼/ì„±ê³µ/ì‹¤íŒ¨ ìš©ì–´ ê¸ˆì§€
    #    - "ì˜ ëëƒ?" âŒ
    #    - "ì–´ë–¤ ì´ìœ ë¡œ ê´€ì¸¡ì´ ëë‚¬ëƒ?" âœ…
    #
    # v1ì—ì„œ í—ˆìš©í•˜ëŠ” exit_type (ê³ ì •, ë³€ê²½ ë¶ˆê°€):
    VALID_EXIT_TYPES = {
        "reached_1pct",    # ê¸°ì¤€ ë°˜ì‘ í­ ë„ë‹¬
        "no_reaction",    # ê´€ì¸¡ ì‹œê°„ ë™ì•ˆ ì˜ë¯¸ ìˆëŠ” ë°˜ì‘ ì—†ìŒ
        "timeout",        # ìµœëŒ€ ê´€ì¸¡ ì‹œê°„ ì´ˆê³¼
        "manual_stop",    # ì‹œìŠ¤í…œ/í…ŒìŠ¤íŠ¸ ì¢…ë£Œ
    }
    # â— ì´ 4ê°œ ì™¸ì—ëŠ” v1ì— ë„£ì§€ ì•ŠëŠ”ë‹¤
    
    # ============================================================
    # exit_type íŒì • ìš°ì„ ìˆœìœ„ (v1 ê³ ì •)
    # ============================================================
    # ê°™ì€ recordì—ì„œ ì—¬ëŸ¬ ì¡°ê±´ì´ ë™ì‹œì— ë§Œì¡±ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ
    # ìš°ì„ ìˆœìœ„ê°€ í•„ìˆ˜
    #
    # v1 ìš°ì„ ìˆœìœ„ (ê³ ì •):
    EXIT_TYPE_PRIORITY = [
        "manual_stop",   # 1ìˆœìœ„: ì‚¬ëŒì´ ë©ˆì¶”ë©´ ê·¸ê²Œ ìµœìš°ì„ 
        "reached_1pct",  # 2ìˆœìœ„: ë°˜ì‘ ë„ë‹¬ì€ ê°€ì¥ ëª…í™•í•œ ì¢…ë£Œ
        "timeout",       # 3ìˆœìœ„: timeoutì€ ì‹œìŠ¤í…œ ì¡°ê±´
        "no_reaction",   # 4ìˆœìœ„: no_reactionì€ "ë‚˜ë¨¸ì§€"
    ]
    
    def select_exit_type(exit_types) -> Optional[str]:
        """
        exit_type ìš°ì„ ìˆœìœ„ì— ë”°ë¼ í•˜ë‚˜ ì„ íƒ
        
        Args:
            exit_types: exit_type ë¬¸ìì—´, ë¦¬ìŠ¤íŠ¸, ë˜ëŠ” None
        
        Returns:
            ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ì„ íƒëœ exit_type (ë¬¸ìì—´) ë˜ëŠ” None
        """
        if not exit_types:
            return None
        
        # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
        if isinstance(exit_types, list):
            exit_type_list = exit_types
        # ë¬¸ìì—´ì¸ ê²½ìš°
        elif isinstance(exit_types, str):
            exit_type_list = [exit_types]
        else:
            return None
        
        # ìœ íš¨í•œ exit_typeë§Œ í•„í„°ë§
        valid_types = [
            et for et in exit_type_list
            if isinstance(et, str) and et in VALID_EXIT_TYPES
        ]
        
        if not valid_types:
            return None
        
        # ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ì²« ë²ˆì§¸ ì„ íƒ
        for priority_type in EXIT_TYPE_PRIORITY:
            if priority_type in valid_types:
                return priority_type
        
        # ìš°ì„ ìˆœìœ„ì— ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ìœ íš¨í•œ íƒ€ì… ë°˜í™˜
        return valid_types[0]
    
    # ============================================================
    # 1. recordë¥¼ ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬ (í•„ìˆ˜)
    # ============================================================
    def get_timestamp(rec: Dict[str, Any]) -> datetime:
        """recordì—ì„œ timestamp ì¶”ì¶œ ë° ë³€í™˜"""
        ts_str = rec.get("meta", {}).get("timestamp", "")
        if not ts_str:
            return datetime.min
        
        try:
            if isinstance(ts_str, str):
                # ISO í˜•ì‹ íŒŒì‹±
                if "T" in ts_str:
                    return datetime.fromisoformat(ts_str.replace("Z", "+00:00"))
                else:
                    return datetime.min
            return ts_str
        except Exception:
            return datetime.min
    
    sorted_records = sorted(records, key=get_timestamp)
    
    # ============================================================
    # 2. Cycle ìƒíƒœ ë¨¸ì‹  (ì¢…ëª©ë³„ IDLE/ACTIVE)
    # ============================================================
    open_cycles: Dict[str, Dict[str, Any]] = {}  # stock_code -> active cycle
    
    # ============================================================
    # 3. record ìˆœíšŒ (ì‹œê°„ìˆœ)
    # ============================================================
    for rec_idx, rec in enumerate(sorted_records):
        meta = rec.get("meta", {})
        stock_code = meta.get("stock_code", "UNKNOWN")
        session = meta.get("session", "UNKNOWN")
        timestamp_str = meta.get("timestamp", "")
        
        # timestampë¥¼ datetime ê°ì²´ë¡œ ë³€í™˜
        try:
            if timestamp_str:
                timestamp_dt = datetime.fromisoformat(
                    timestamp_str.replace("Z", "+00:00")
                )
            else:
                timestamp_dt = None
        except Exception:
            timestamp_dt = None
        
        # record: observerê°€ í•œ ë²ˆ ì‹¤í–‰ëœ ë¡œê·¸
        stats["by_stock"][stock_code]["records"] += 1
        stats["session_distribution"][session] += 1
        
        # trigger: ê´€ì¸¡ ì¡°ê±´ì„ ë§Œì¡±í•œ 'ì‚¬ê±´'
        observer = rec.get("observer", {})
        is_triggered = observer.get("triggered", False)
        
        if is_triggered:
            stats["observer_summary"]["triggered_records"] += 1
            stats["observer_summary"]["triggered_stocks"].add(stock_code)
            stats["by_stock"][stock_code]["triggered_records"] += 1
            
            if timestamp_str:
                # trigger ì •ë³´ ì €ì¥
                stats["observer_summary"]["triggers"].append({
                    "stock": stock_code,
                    "time": timestamp_str,
                    "session": session,
                    "record_index": rec_idx,
                })
        
        # ============================================================
        # 4. Cycle ì‹œì‘ íŒì • (IDLE -> ACTIVE)
        # ============================================================
        if stock_code not in open_cycles:
            # ìƒíƒœ: IDLE
            if is_triggered:
                # cycle START
                open_cycles[stock_code] = {
                    "stock": stock_code,
                    "start_time": timestamp_dt if timestamp_dt else None,
                    "start_time_str": timestamp_str,
                    "start_record_index": rec_idx,
                    "start_session": session,
                    "trigger_type": "observer_triggered",
                    "records_in_cycle": 1,
                }
        else:
            # ìƒíƒœ: ACTIVE
            # cycleì´ ì—´ë ¤ìˆìœ¼ë©´ record ìˆ˜ ì¦ê°€
            open_cycles[stock_code]["records_in_cycle"] += 1
        
        # ============================================================
        # 5. Cycle ì¢…ë£Œ íŒì • (ACTIVE -> IDLE)
        # ============================================================
        if stock_code in open_cycles:
            outcome = rec.get("outcome", {})
            raw_exit_type = outcome.get("exit_type")
            
            # exit_type ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ì„ íƒ
            exit_type = select_exit_type(raw_exit_type)
            
            # exit_type ê²€ì¦ ë° ì²˜ë¦¬
            if exit_type:
                # ìœ íš¨í•œ exit_type: cycle ì¢…ë£Œ
                cycle = open_cycles[stock_code]
                # datetime ê°ì²´ëŠ” ë¬¸ìì—´ë¡œ ì €ì¥ (JSON ì§ë ¬í™”ë¥¼ ìœ„í•´)
                cycle["end_time"] = timestamp_dt if timestamp_dt else None
                cycle["end_time_str"] = timestamp_str
                cycle["end_record_index"] = rec_idx
                cycle["end_session"] = session
                cycle["exit_type"] = exit_type
                
                # ì™„ì „íˆ ì¢…ë£Œëœ cycleì„ triggered_cycleì— ì¶”ê°€
                # datetime ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
                cycle_copy = cycle.copy()
                if cycle_copy.get("start_time"):
                    if isinstance(cycle_copy["start_time"], datetime):
                        cycle_copy["start_time"] = (
                            cycle_copy["start_time"].isoformat()
                        )
                if cycle_copy.get("end_time"):
                    if isinstance(cycle_copy["end_time"], datetime):
                        cycle_copy["end_time"] = (
                            cycle_copy["end_time"].isoformat()
                        )
                stats["observer_summary"]["triggered_cycle"].append(
                    cycle_copy
                )
                
                # active_cyclesì—ì„œ ì œê±° (IDLEë¡œ ì „í™˜)
                del open_cycles[stock_code]
            elif raw_exit_type:
                # exit_typeì´ ìˆì§€ë§Œ ìœ íš¨í•˜ì§€ ì•ŠìŒ: ê²½ê³  ë¡œê·¸
                print(
                    f"âš ï¸  ì˜ëª»ëœ exit_type: {raw_exit_type} "
                    f"(ì¢…ëª©: {stock_code}, record_index: {rec_idx})"
                )
                print(
                    f"    í—ˆìš©ë˜ëŠ” exit_type: {VALID_EXIT_TYPES}"
                )
                # ì˜ëª»ëœ exit_typeì€ ë¬´ì‹œí•˜ê³  cycleì€ ê³„ì† ì§„í–‰
        
        # Box ì§‘ê³„
        box = rec.get("box", {})
        if box.get("formed", False):
            stats["box_summary"]["formed_count"] += 1
            stats["box_summary"]["formed_stocks"].add(stock_code)
            stats["by_stock"][stock_code]["box_formed"] += 1
        
        # Base Candle ì§‘ê³„
        base_candle = rec.get("base_candle", {})
        if base_candle.get("exists", False):
            stats["base_candle_summary"]["exists_count"] += 1
            stats["base_candle_summary"]["exists_stocks"].add(stock_code)
            stats["by_stock"][stock_code]["base_candle_exists"] += 1
        
        # ì´ë²¤íŠ¸ ë¯¸ë°œìƒ ì‚¬ìœ  ì§‘ê³„
        no_event_reasons = rec.get("no_event_reason", [])
        for reason in no_event_reasons:
            stats["no_event_reasons"][reason] += 1
    
    # ============================================================
    # 6. ì¥ ì¢…ë£Œ ì‹œ ë¯¸ì¢…ë£Œ cycle ì²˜ë¦¬
    # ============================================================
    # ë§ˆì§€ë§‰ recordì˜ timestampë¥¼ ì¥ ì¢…ë£Œ ì‹œê°ìœ¼ë¡œ ì‚¬ìš©
    market_close_time = None
    if sorted_records:
        last_rec = sorted_records[-1]
        last_ts_str = last_rec.get("meta", {}).get("timestamp", "")
        if last_ts_str:
            try:
                market_close_time = datetime.fromisoformat(
                    last_ts_str.replace("Z", "+00:00")
                )
            except Exception:
                pass
    
    for stock_code, cycle in open_cycles.items():
        # ë¯¸ì¢…ë£Œ cycleì„ timeoutìœ¼ë¡œ ì¢…ë£Œ ì²˜ë¦¬
        cycle["end_time"] = market_close_time
        cycle["end_time_str"] = last_ts_str if last_ts_str else ""
        cycle["exit_type"] = "timeout"
        cycle["end_reason"] = "session_end"
        
        # ë¯¸ì¢…ë£Œ cycleë„ triggered_cycleì— ì¶”ê°€ (ì •ì±… ì„ íƒ)
        stats["observer_summary"]["triggered_cycle"].append(cycle.copy())
    
    # ============================================================
    # 7. Cycle ìš”ì•½ ìƒì„± (êµ¬ì¡° ì •ë³´ë§Œ)
    # ============================================================
    summary_cycles = []
    date_str = sorted_records[0].get("meta", {}).get("date", "") if sorted_records else ""
    
    for i, cycle in enumerate(stats["observer_summary"]["triggered_cycle"], start=1):
        # start_timeê³¼ end_timeì´ datetime ë˜ëŠ” ë¬¸ìì—´ì¼ ìˆ˜ ìˆìŒ
        start_dt = cycle.get("start_time")
        end_dt = cycle.get("end_time")
        
        # ë¬¸ìì—´ì¸ ê²½ìš° datetimeìœ¼ë¡œ ë³€í™˜
        if isinstance(start_dt, str):
            try:
                start_dt = datetime.fromisoformat(
                    start_dt.replace("Z", "+00:00")
                )
            except Exception:
                start_dt = None
        if isinstance(end_dt, str):
            try:
                end_dt = datetime.fromisoformat(
                    end_dt.replace("Z", "+00:00")
                )
            except Exception:
                end_dt = None
        
        duration_sec = 0
        if start_dt and end_dt:
            try:
                duration_sec = int((end_dt - start_dt).total_seconds())
            except Exception:
                pass
        
        # start_time_strê³¼ end_time_str ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ datetimeì„ ë¬¸ìì—´ë¡œ ë³€í™˜
        start_time_str = cycle.get("start_time_str", "")
        if not start_time_str and start_dt:
            start_time_str = start_dt.isoformat()
        
        end_time_str = cycle.get("end_time_str", "")
        if not end_time_str and end_dt:
            end_time_str = end_dt.isoformat()
        
        summary_cycles.append({
            "cycle_id": f"{date_str}-{cycle['stock']}-{i:02d}",
            "stock": cycle["stock"],
            "start_time": start_time_str,
            "end_time": end_time_str,
            "duration_sec": duration_sec,
            "exit_type": cycle.get("exit_type", "unknown"),
        })
    
    # ìš”ì•½ì„ observer_summaryì— ì¶”ê°€
    stats["observer_summary"]["cycle_summary"] = summary_cycles
    
    # ============================================================
    # 8. ìµœì¢… í†µê³„ ê³„ì‚°
    # ============================================================
    stats["observer_summary"]["triggered_cycles_count"] = len(
        stats["observer_summary"]["triggered_cycle"]
    )
    stats["observer_summary"]["open_cycles_count"] = len(open_cycles)
    
    # setì„ listë¡œ ë³€í™˜ (JSON ì§ë ¬í™”ë¥¼ ìœ„í•´)
    stats["observer_summary"]["triggered_stocks"] = list(
        stats["observer_summary"]["triggered_stocks"]
    )
    stats["box_summary"]["formed_stocks"] = list(
        stats["box_summary"]["formed_stocks"]
    )
    stats["base_candle_summary"]["exists_stocks"] = list(
        stats["base_candle_summary"]["exists_stocks"]
    )
    stats["session_distribution"] = dict(stats["session_distribution"])
    stats["no_event_reasons"] = dict(stats["no_event_reasons"])
    
    return stats


def aggregate_reasons(
    date: str,
    records: List[Dict[str, Any]],
) -> Dict[str, Any]:
    """Reason ì§‘ê³„ (watchlist ì„ ì • ì‚¬ìœ )"""
    # watchlist JSON íŒŒì¼ ì½ê¸°
    watchlist_path = os.path.join(
        PROJECT_ROOT,
        "scout_selector",
        "output",
        f"watchlist_{date.replace('-', '')}.json"
    )
    
    reason_stats = {
        "by_bucket": defaultdict(lambda: {
            "count": 0,
            "stocks": [],
            "avg_score": 0.0,
        }),
        "top_reasons": [],
        "watchlist_loaded": False,
    }
    
    if not os.path.exists(watchlist_path):
        return reason_stats
    
    try:
        with open(watchlist_path, "r", encoding="utf-8") as f:
            watchlist_data = json.load(f)
        
        reason_stats["watchlist_loaded"] = True
        
        # ê° ë²„í‚·ë³„ reason ì§‘ê³„
        for bucket in ["largecap", "volume", "structure", "theme"]:
            stocks = watchlist_data.get(bucket, [])
            if not isinstance(stocks, list):
                continue
            
            scores = []
            for stock in stocks:
                if isinstance(stock, dict):
                    symbol = stock.get("symbol", "")
                    score = stock.get("score", 0.0)
                    reason = stock.get("reason", {})
                    
                    reason_stats["by_bucket"][bucket]["stocks"].append({
                        "symbol": symbol,
                        "score": score,
                        "reason": reason,
                    })
                    scores.append(score)
                elif isinstance(stock, str):
                    # êµ¬ë²„ì „ í˜¸í™˜ (íŠœí”Œ í˜•ì‹)
                    reason_stats["by_bucket"][bucket]["stocks"].append({
                        "symbol": stock,
                        "score": 0.0,
                        "reason": {},
                    })
            
            reason_stats["by_bucket"][bucket]["count"] = len(stocks)
            if scores:
                reason_stats["by_bucket"][bucket]["avg_score"] = (
                    sum(scores) / len(scores)
                )
        
        # dictë¥¼ ì¼ë°˜ dictë¡œ ë³€í™˜ (JSON ì§ë ¬í™”ë¥¼ ìœ„í•´)
        reason_stats["by_bucket"] = dict(reason_stats["by_bucket"])
        for bucket in reason_stats["by_bucket"]:
            reason_stats["by_bucket"][bucket] = dict(
                reason_stats["by_bucket"][bucket]
            )
        
    except Exception as e:
        print(f"âš ï¸  Watchlist ì½ê¸° ì˜¤ë¥˜: {e}")
    
    return reason_stats


# ===============================
# ìƒìœ„ 100 ê²°ê³¼ ì½ê¸° (ì„ íƒ)
# ===============================
def load_top_100_results(date: Optional[str] = None) -> List[Dict[str, Any]]:
    """
    ìƒìœ„ 100 ê²°ê³¼ ì½ê¸° (ì„ íƒ ê¸°ëŠ¥)
    
    TODO: ì‹¤ì œ ìƒìœ„ 100 ê²°ê³¼ íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì•¼ í•¨
    """
    if date is None:
        date = datetime.now().strftime("%Y-%m-%d")
    
    # ì˜ˆì‹œ: daily_scan ê²°ê³¼ë¥¼ ì½ëŠ”ë‹¤ê³  ê°€ì •
    top_100_path = os.path.join(
        PROJECT_ROOT,
        "test",
        "daily_scan",
        "output",
        f"top_100_{date.replace('-', '')}.csv"
    )
    
    if not os.path.exists(top_100_path):
        return []
    
    # CSV ì½ê¸° (ê°„ë‹¨í•œ êµ¬í˜„)
    results = []
    try:
        import csv
        with open(top_100_path, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            for row in reader:
                results.append(row)
    except Exception as e:
        print(f"âš ï¸  ìƒìœ„ 100 ê²°ê³¼ ì½ê¸° ì˜¤ë¥˜: {e}")
    
    return results


# ===============================
# ì‹œì¥ ì„±ê²© ìš”ì•½ ìƒì„±
# ===============================
def generate_market_character_summary(
    observer_stats: Dict[str, Any],
    records: List[Dict[str, Any]],
    top_100_results: Optional[List[Dict[str, Any]]] = None,
) -> Dict[str, Any]:
    """ì‹œì¥ ì„±ê²© ìš”ì•½ ìƒì„±"""
    
    total_records = len(records)
    triggered_records = observer_stats["observer_summary"]["triggered_records"]
    box_formed = observer_stats["box_summary"]["formed_count"]
    
    # ê¸°ë³¸ í†µê³„
    trigger_rate = (
        triggered_records / total_records * 100
        if total_records > 0
        else 0
    )
    box_rate = (
        box_formed / total_records * 100
        if total_records > 0
        else 0
    )
    
    # ì‹œì¥ ì„±ê²© íŒë‹¨
    market_character = {
        "date": records[0]["meta"]["date"] if records else "",
        "total_scouts": total_records,
        "trigger_rate": round(trigger_rate, 2),
        "box_rate": round(box_rate, 2),
        "active_stocks": len(observer_stats["observer_summary"]["triggered_stocks"]),
        "session_distribution": observer_stats["session_distribution"],
        "character": "UNKNOWN",
        "description": "",
    }
    
    # ì‹œì¥ ì„±ê²© ë¶„ë¥˜
    if trigger_rate >= 20:
        market_character["character"] = "ACTIVE"
        market_character["description"] = (
            "í™œë°œí•œ ì‹œì¥: Observer íŠ¸ë¦¬ê±° ë¹„ìœ¨ì´ ë†’ìŒ. "
            "ê¸°íšŒê°€ ë§ì€ ë‚ ë¡œ íŒë‹¨ë¨."
        )
    elif trigger_rate >= 10:
        market_character["character"] = "MODERATE"
        market_character["description"] = (
            "ë³´í†µ ì‹œì¥: ì ë‹¹í•œ ê¸°íšŒê°€ ìˆì—ˆë˜ ë‚ ."
        )
    elif trigger_rate >= 5:
        market_character["character"] = "QUIET"
        market_character["description"] = (
            "ì¡°ìš©í•œ ì‹œì¥: ê¸°íšŒê°€ ì ì—ˆë˜ ë‚ ."
        )
    else:
        market_character["character"] = "DEAD"
        market_character["description"] = (
            "ì¹¨ì²´ ì‹œì¥: ê±°ì˜ ê¸°íšŒê°€ ì—†ì—ˆë˜ ë‚ ."
        )
    
    # Box í˜•ì„± ë¹„ìœ¨ ì¶”ê°€ ë¶„ì„
    if box_rate >= 30:
        market_character["description"] += (
            " Box í˜•ì„± ë¹„ìœ¨ì´ ë†’ì•„ íŒ¨í„´ í˜•ì„±ì´ í™œë°œí•¨."
        )
    elif box_rate < 10:
        market_character["description"] += (
            " Box í˜•ì„± ë¹„ìœ¨ì´ ë‚®ì•„ íŒ¨í„´ í˜•ì„±ì´ ë¶€ì¡±í•¨."
        )
    
    return market_character


# ===============================
# ì¼ì¼ í‰ê°€ ê¸°ë¡ ì €ì¥
# ===============================
def save_daily_analysis(
    date: str,
    observer_stats: Dict[str, Any],
    market_character: Dict[str, Any],
    reason_stats: Optional[Dict[str, Any]] = None,
    top_100_results: Optional[List[Dict[str, Any]]] = None,
) -> Dict[str, str]:
    """ì¼ì¼ í‰ê°€ ê¸°ë¡ ì €ì¥"""
    
    date_dir = os.path.join(ANALYSIS_OUTPUT_DIR, date)
    os.makedirs(date_dir, exist_ok=True)
    
    # JSON ì €ì¥
    json_path = os.path.join(date_dir, "daily_analysis.json")
    
    # datetime ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    def convert_datetime_for_json(obj):
        """datetime ê°ì²´ë¥¼ ISO ë¬¸ìì—´ë¡œ ë³€í™˜"""
        if isinstance(obj, datetime):
            return obj.isoformat()
        elif isinstance(obj, dict):
            return {k: convert_datetime_for_json(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [convert_datetime_for_json(item) for item in obj]
        elif isinstance(obj, set):
            return list(obj)  # setì„ listë¡œ ë³€í™˜
        return obj
    
    analysis_data = {
        "date": date,
        "generated_at": datetime.now().isoformat(),
        "observer_stats": convert_datetime_for_json(observer_stats),
        "reason_stats": reason_stats or {},
        "market_character": market_character,
        "top_100_available": top_100_results is not None and len(top_100_results) > 0,
    }
    
    if top_100_results:
        analysis_data["top_100_count"] = len(top_100_results)
    
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(analysis_data, f, ensure_ascii=False, indent=2)
    
    # TXT ìš”ì•½ ì €ì¥ (ì‚¬ëŒìš©)
    txt_path = os.path.join(date_dir, "daily_analysis.txt")
    with open(txt_path, "w", encoding="utf-8") as f:
        f.write("=" * 60 + "\n")
        f.write(f"ì¼ì¼ ì‹œì¥ ë¶„ì„ ìš”ì•½ - {date}\n")
        f.write("=" * 60 + "\n\n")
        
        f.write("ğŸ“Š ê¸°ë³¸ í†µê³„\n")
        f.write(f"  ì´ ì •ì°° íšŸìˆ˜ (total_records): {observer_stats['total_records']}\n")
        f.write(f"  ê´€ì°° ì¢…ëª© ìˆ˜: {len(observer_stats['by_stock'])}\n")
        f.write(f"  Triggered Records: {observer_stats['observer_summary']['triggered_records']}íšŒ\n")
        cycles_count = observer_stats['observer_summary'].get(
            'triggered_cycles_count', 0
        )
        open_count = observer_stats['observer_summary'].get(
            'open_cycles_count', 0
        )
        f.write(f"  ì™„ì „íˆ ì¢…ë£Œëœ Cycles: {cycles_count}ê°œ\n")
        if open_count > 0:
            f.write(f"  ì¥ ì¢…ë£Œ ì‹œ ë¯¸ì¢…ë£Œ Cycles: {open_count}ê°œ\n")
        f.write(f"  Box í˜•ì„±: {observer_stats['box_summary']['formed_count']}íšŒ\n")
        f.write(f"  Base Candle ì¡´ì¬: {observer_stats['base_candle_summary']['exists_count']}íšŒ\n\n")
        
        f.write("ğŸ“ˆ ì‹œì¥ ì„±ê²©\n")
        f.write(f"  ë¶„ë¥˜: {market_character['character']}\n")
        f.write(f"  íŠ¸ë¦¬ê±° ë¹„ìœ¨: {market_character['trigger_rate']}%\n")
        f.write(f"  Box ë¹„ìœ¨: {market_character['box_rate']}%\n")
        f.write(f"  í™œì„± ì¢…ëª© ìˆ˜: {market_character['active_stocks']}\n")
        f.write(f"  ì„¤ëª…: {market_character['description']}\n\n")
        
        f.write("â° ì„¸ì…˜ ë¶„í¬\n")
        for session, count in market_character['session_distribution'].items():
            f.write(f"  {session}: {count}íšŒ\n")
        
        if observer_stats['no_event_reasons']:
            f.write("\nâŒ ì´ë²¤íŠ¸ ë¯¸ë°œìƒ ì‚¬ìœ \n")
            for reason, count in sorted(
                observer_stats['no_event_reasons'].items(),
                key=lambda x: x[1],
                reverse=True
            )[:10]:
                f.write(f"  {reason}: {count}íšŒ\n")
        
        if observer_stats['observer_summary']['triggers']:
            f.write("\nğŸ¯ Observer íŠ¸ë¦¬ê±° (Trigger Events)\n")
            for trigger in observer_stats['observer_summary']['triggers'][:20]:
                f.write(
                    f"  {trigger['stock']} - "
                    f"{trigger['time']} ({trigger['session']})\n"
                )
        
        # Cycle ìš”ì•½ ì •ë³´ (êµ¬ì¡° ì •ë³´ë§Œ)
        cycle_summary = observer_stats['observer_summary'].get(
            'cycle_summary', []
        )
        if cycle_summary:
            f.write("\nğŸ”„ Cycle ìš”ì•½ (êµ¬ì¡° ì •ë³´)\n")
            f.write(f"  ì´ {len(cycle_summary)}ê°œ\n\n")
            for cycle in cycle_summary[:20]:
                f.write(f"  Cycle ID: {cycle['cycle_id']}\n")
                f.write(f"    ì¢…ëª©: {cycle['stock']}\n")
                f.write(f"    ì‹œì‘: {cycle['start_time']}\n")
                f.write(f"    ì¢…ë£Œ: {cycle['end_time']}\n")
                f.write(f"    ì§€ì† ì‹œê°„: {cycle['duration_sec']}ì´ˆ\n")
                f.write(f"    ì¢…ë£Œ ì‚¬ìœ : {cycle['exit_type']}\n")
                f.write("\n")
        
        if reason_stats and reason_stats.get('watchlist_loaded'):
            f.write("\nğŸ“‹ Watchlist ì„ ì • ì‚¬ìœ \n")
            for bucket, data in reason_stats['by_bucket'].items():
                f.write(f"  {bucket}: {data['count']}ì¢…ëª© (í‰ê·  ì ìˆ˜: {data['avg_score']:.2f})\n")
    
    return {
        "json_path": json_path,
        "txt_path": txt_path,
    }


# ===============================
# ë©”ì¸ ë¶„ì„ í•¨ìˆ˜
# ===============================
def analyze_daily_market(
    date: Optional[str] = None,
    include_top_100: bool = False,
    with_graphs: bool = False,
) -> Dict[str, Any]:
    """
    ì¼ì¼ ì‹œì¥ ë¶„ì„ ì‹¤í–‰
    
    Args:
        date: ë¶„ì„í•  ë‚ ì§œ (YYYY-MM-DD), Noneì´ë©´ ì˜¤ëŠ˜
        include_top_100: ìƒìœ„ 100 ê²°ê³¼ í¬í•¨ ì—¬ë¶€
    
    Returns:
        ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    if date is None:
        date = datetime.now().strftime("%Y-%m-%d")
    
    print(f"ğŸ“Š ì¼ì¼ ì‹œì¥ ë¶„ì„ ì‹œì‘: {date}")
    
    # âœ… ì œì™¸ëœ ë‚ ì§œ í™•ì¸
    if date in EXCLUDED_DATES:
        msg = f"  âš ï¸  {date}ëŠ” ë¶„ì„ì—ì„œ ì œì™¸ëœ ë‚ ì§œì…ë‹ˆë‹¤ (í…ŒìŠ¤íŠ¸ ë°ì´í„°)"
        print(msg)
        excluded_msg = (
            f"{date}ëŠ” ë¶„ì„ì—ì„œ ì œì™¸ëœ ë‚ ì§œì…ë‹ˆë‹¤ (í…ŒìŠ¤íŠ¸ ë°ì´í„°). "
            f"ì²« ì •ìƒ ë°ì´í„° ë‚ ì§œ: {FIRST_VALID_DATE}"
        )
        return {
            "date": date,
            "error": "excluded_date",
            "message": excluded_msg,
            "excluded": True,
            "first_valid_date": FIRST_VALID_DATE,
        }
    
    # 1. ì •ì°° ê¸°ë¡ ë¡œë“œ
    print("  ğŸ“‚ ì •ì°° ê¸°ë¡ ë¡œë“œ ì¤‘...")
    records = load_scout_records(date)
    
    if not records:
        print(f"  âš ï¸  {date}ì˜ ì •ì°° ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        return {
            "date": date,
            "error": "no_records",
            "message": f"{date}ì˜ ì •ì°° ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.",
        }
    
    print(f"  âœ… {len(records)}ê°œì˜ ê¸°ë¡ ë¡œë“œ ì™„ë£Œ")
    
    # 2. Observer/Reason ì§‘ê³„
    print("  ğŸ“ˆ Observer/Reason ì§‘ê³„ ì¤‘...")
    observer_stats = aggregate_observers(records)
    reason_stats = aggregate_reasons(date, records)
    
    # 3. ìƒìœ„ 100 ê²°ê³¼ ì½ê¸° (ì„ íƒ)
    top_100_results = None
    if include_top_100:
        print("  ğŸ“Š ìƒìœ„ 100 ê²°ê³¼ ì½ê¸° ì¤‘...")
        top_100_results = load_top_100_results(date)
        if top_100_results:
            print(f"  âœ… {len(top_100_results)}ê°œ ê²°ê³¼ ë¡œë“œ ì™„ë£Œ")
    
    # 4. ì‹œì¥ ì„±ê²© ìš”ì•½ ìƒì„±
    print("  ğŸ¯ ì‹œì¥ ì„±ê²© ìš”ì•½ ìƒì„± ì¤‘...")
    market_character = generate_market_character_summary(
        observer_stats,
        records,
        top_100_results,
    )
    
    # 5. ì¼ì¼ í‰ê°€ ê¸°ë¡ ì €ì¥
    print("  ğŸ’¾ ì¼ì¼ í‰ê°€ ê¸°ë¡ ì €ì¥ ì¤‘...")
    saved_paths = save_daily_analysis(
        date,
        observer_stats,
        market_character,
        reason_stats,
        top_100_results,
    )
    
    # 6. Daily Report ìŠ¤í‚¤ë§ˆ ìƒì„± (ê³„ì•½ìš©)
    print("  ğŸ“‹ Daily Report ìŠ¤í‚¤ë§ˆ ìƒì„± ì¤‘...")
    try:
        from test.framework.analyzer.daily_report_builder import (
            build_daily_report,
            save_daily_report,
        )
        
        daily_report = build_daily_report(
            date=date,
            observer_stats=observer_stats,
            scout_version="scout_v1",
            test_mode=True,
        )
        
        date_dir = os.path.join(ANALYSIS_OUTPUT_DIR, date)
        report_path = save_daily_report(daily_report, date_dir)
        print(f"     Report: {report_path}")
        
        # 7. ê·¸ë˜í”„ ìƒì„± (ì„ íƒì )
        graphs_dir = None
        if with_graphs:
            print("  ğŸ“Š ê·¸ë˜í”„ ìƒì„± ì¤‘...")
            try:
                from test.framework.analyzer.graph_generator import (
                    generate_daily_graphs,
                )
                
                graphs_dir = os.path.join(date_dir, "daily_graphs")
                graph_results = generate_daily_graphs(report_path, graphs_dir)
                
                if any(graph_results.values()):
                    print(f"     Graphs: {graphs_dir}")
                else:
                    print("  âš ï¸  ê·¸ë˜í”„ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"  âš ï¸  ê·¸ë˜í”„ ìƒì„± ì˜¤ë¥˜: {e}")
                graphs_dir = None
    except Exception as e:
        print(f"  âš ï¸  Daily Report ìƒì„± ì˜¤ë¥˜: {e}")
        report_path = None
        graphs_dir = None
    
    print("  âœ… ì €ì¥ ì™„ë£Œ:")
    print(f"     JSON: {saved_paths['json_path']}")
    print(f"     TXT:  {saved_paths['txt_path']}")
    if report_path:
        print(f"     Report: {report_path}")
        saved_paths["report_path"] = report_path
    if graphs_dir:
        print(f"     Graphs: {graphs_dir}")
        saved_paths["graphs_dir"] = graphs_dir
    
    return {
        "date": date,
        "total_records": len(records),
        "observer_stats": observer_stats,
        "market_character": market_character,
        "saved_paths": saved_paths,
    }


if __name__ == "__main__":
    import sys
    
    date = None
    include_top_100 = False
    
    if len(sys.argv) > 1:
        date = sys.argv[1]
    if len(sys.argv) > 2 and sys.argv[2] == "--top100":
        include_top_100 = True
    
    result = analyze_daily_market(date, include_top_100)
    
    if "error" in result:
        print(f"\nâŒ ì˜¤ë¥˜: {result['message']}")
        sys.exit(1)
    
    print("\nâœ… ë¶„ì„ ì™„ë£Œ!")

